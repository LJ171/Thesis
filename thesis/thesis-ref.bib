
@article{meilicke_reinforced_2020,
	title = {Reinforced {Anytime} {Bottom} {Up} {Rule} {Learning} for {Knowledge} {Graph} {Completion}},
	url = {http://arxiv.org/abs/2004.04412},
	abstract = {Most of todays work on knowledge graph completion is concerned with sub-symbolic approaches that focus on the concept of embedding a given graph in a low dimensional vector space. Against this trend, we propose an approach called AnyBURL that is rooted in the symbolic space. Its core algorithm is based on sampling paths, which are generalized into Horn rules. Previously published results show that the prediction quality of AnyBURL is on the same level as current state of the art with the additional benefit of offering an explanation for the predicted fact. In this paper, we are concerned with two extensions of AnyBURL. Firstly, we change AnyBURLs interpretation of rules from \${\textbackslash}Theta\$-subsumption into \${\textbackslash}Theta\$-subsumption under Object Identity. Secondly, we introduce reinforcement learning to better guide the sampling process. We found out that reinforcement learning helps finding more valuable rules earlier in the search process. We measure the impact of both extensions and compare the resulting approach with current state of the art approaches. Our results show that AnyBURL outperforms most sub-symbolic methods.},
	urldate = {2022-01-28},
	journal = {arXiv:2004.04412 [cs]},
	author = {Meilicke, Christian and Chekol, Melisachew Wudage and Fink, Manuel and Stuckenschmidt, Heiner},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.04412},
	keywords = {\#todo},
	file = {arXiv Fulltext PDF:C\:\\Users\\larsj\\Zotero\\storage\\9CUA3UJU\\Meilicke et al. - 2020 - Reinforced Anytime Bottom Up Rule Learning for Kno.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\larsj\\Zotero\\storage\\BP23X9VL\\2004.html:text/html},
}

@misc{meilicke_anyburl_2022,
	title = {{AnyBURL}},
	url = {https://web.informatik.uni-mannheim.de/AnyBURL/},
	urldate = {2022-01-28},
	author = {Meilicke, Christian},
	month = jan,
	year = {2022},
	keywords = {\#todo},
	file = {AnyBURL:C\:\\Users\\larsj\\Zotero\\storage\\APKG3PFJ\\AnyBURL.html:text/html},
}

@article{ott_safran_2021,
	title = {{SAFRAN}: {An} interpretable, rule-based link prediction method outperforming embedding models},
	shorttitle = {{SAFRAN}},
	url = {http://arxiv.org/abs/2109.08002},
	abstract = {Neural embedding-based machine learning models have shown promise for predicting novel links in knowledge graphs. Unfortunately, their practical utility is diminished by their lack of interpretability. Recently, the fully interpretable, rule-based algorithm AnyBURL yielded highly competitive results on many general-purpose link prediction benchmarks. However, current approaches for aggregating predictions made by multiple rules are affected by redundancies. We improve upon AnyBURL by introducing the SAFRAN rule application framework, which uses a novel aggregation approach called Non-redundant Noisy-OR that detects and clusters redundant rules prior to aggregation. SAFRAN yields new state-of-the-art results for fully interpretable link prediction on the established general-purpose benchmarks FB15K-237, WN18RR and YAGO3-10. Furthermore, it exceeds the results of multiple established embedding-based algorithms on FB15K-237 and WN18RR and narrows the gap between rule-based and embedding-based algorithms on YAGO3-10.},
	urldate = {2022-01-28},
	journal = {arXiv:2109.08002 [cs]},
	author = {Ott, Simon and Meilicke, Christian and Samwald, Matthias},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.08002},
	keywords = {\#todo},
	file = {arXiv Fulltext PDF:C\:\\Users\\larsj\\Zotero\\storage\\VJGH5TY3\\Ott et al. - 2021 - SAFRAN An interpretable, rule-based link predicti.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\larsj\\Zotero\\storage\\86XBDNEQ\\2109.html:text/html},
}

@misc{noauthor_uma-pi1kge_2022,
	title = {uma-pi1/kge},
	copyright = {MIT},
	url = {https://github.com/uma-pi1/kge},
	abstract = {LibKGE - A knowledge graph embedding library for reproducible research},
	urldate = {2022-01-28},
	publisher = {Chair of Data Analytics, University of Mannheim, Germany},
	month = jan,
	year = {2022},
	note = {original-date: 2019-02-22T18:39:36Z},
}

@inproceedings{meilicke_anytime_2019,
	address = {Macao, China},
	title = {Anytime {Bottom}-{Up} {Rule} {Learning} for {Knowledge} {Graph} {Completion}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/435},
	doi = {10.24963/ijcai.2019/435},
	abstract = {We propose an anytime bottom-up technique for learning logical rules from large knowledge graphs. We apply the learned rules to predict candidates in the context of knowledge graph completion. Our approach outperforms other rule-based approaches and it is competitive with current state of the art, which is based on latent representations. Besides, our approach is significantly faster, requires less computational resources, and yields an explanation in terms of the rules that propose a candidate.},
	language = {en},
	urldate = {2022-01-28},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Meilicke, Christian and Chekol, Melisachew Wudage and Ruffinelli, Daniel and Stuckenschmidt, Heiner},
	month = aug,
	year = {2019},
	keywords = {\#todo},
	pages = {3137--3143},
	file = {Meilicke et al. - 2019 - Anytime Bottom-Up Rule Learning for Knowledge Grap.pdf:C\:\\Users\\larsj\\Zotero\\storage\\XXW898RH\\Meilicke et al. - 2019 - Anytime Bottom-Up Rule Learning for Knowledge Grap.pdf:application/pdf},
}

@article{meilicke_why_nodate,
	title = {Why a {Naive} {Way} to {Combine} {Symbolic} and {Latent} {Knowledge} {Base} {Completion} {Works} {Surprisingly} {Well}},
	abstract = {We compare a rule-based approach for knowledge graph completion against current state-of-the-art, which is based on embeddings. Instead of focusing on aggregated metrics, we look at several examples that illustrate essential differences between symbolic and latent approaches. Based on our insights, we construct a simple method to combine the outcome of rule-based and latent approaches in a post-processing step. Our method improves the results constantly for each model and dataset used in our experiments.},
	language = {en},
	author = {Meilicke, Christian and Betz, Patrick and Stuckenschmidt, Heiner},
	keywords = {\#todo},
	pages = {26},
	file = {Meilicke et al. - Why a Naive Way to Combine Symbolic and Latent Kno.pdf:C\:\\Users\\larsj\\Zotero\\storage\\98EZQLT8\\Meilicke et al. - Why a Naive Way to Combine Symbolic and Latent Kno.pdf:application/pdf},
}

@inproceedings{socher_reasoning_2013,
	title = {Reasoning {With} {Neural} {Tensor} {Networks} for {Knowledge} {Base} {Completion}},
	volume = {26},
	url = {https://proceedings.neurips.cc/paper/2013/hash/b337e84de8752b27eda3a12363109e80-Abstract.html},
	urldate = {2022-01-28},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Socher, Richard and Chen, Danqi and Manning, Christopher D and Ng, Andrew},
	year = {2013},
	file = {Full Text PDF:C\:\\Users\\larsj\\Zotero\\storage\\TGCF4WEF\\Socher et al. - 2013 - Reasoning With Neural Tensor Networks for Knowledg.pdf:application/pdf},
}

@inproceedings{bordes_learning_2011,
	title = {Learning {Structured} {Embeddings} of {Knowledge} {Bases}},
	copyright = {Authors who publish a paper in this conference agree to the following terms:   Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.  The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.  The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys{\textquoteright} fees incurred therein.  Author(s) retain all proprietary rights other than copyright (such as patent rights).  Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.  Author(s) may reproduce, or have reproduced, their article/paper for the author{\textquoteright}s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author{\textquoteright}s employer, and then only on the author{\textquoteright}s or the employer{\textquoteright}s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author{\textquoteright}s or the employer{\textquoteright}s creation (including tables of contents with links to other papers) without AAAI{\textquoteright}s written permission.  Author(s) may make limited distribution of all or portions of their article/paper prior to publication.  In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.  In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
	url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI11/paper/view/3659},
	abstract = {Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigorous symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like nat- ural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classification, image semantic annotation, ...) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning meth- ods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text.},
	language = {en},
	urldate = {2022-01-28},
	booktitle = {Twenty-{Fifth} {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Bordes, Antoine and Weston, Jason and Collobert, Ronan and Bengio, Yoshua},
	month = aug,
	year = {2011},
	file = {Full Text PDF:C\:\\Users\\larsj\\Zotero\\storage\\8JNI9V6R\\Bordes et al. - 2011 - Learning Structured Embeddings of Knowledge Bases.pdf:application/pdf;Snapshot:C\:\\Users\\larsj\\Zotero\\storage\\UW7QSGHS\\3659.html:text/html},
}

@inproceedings{bordes_translating_2013,
	title = {Translating {Embeddings} for {Modeling} {Multi}-relational {Data}},
	volume = {26},
	url = {https://papers.nips.cc/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html},
	urldate = {2022-01-28},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
	year = {2013},
	file = {Full Text PDF:C\:\\Users\\larsj\\Zotero\\storage\\EBUB82X5\\Bordes et al. - 2013 - Translating Embeddings for Modeling Multi-relation.pdf:application/pdf},
}

@inproceedings{ji_knowledge_2015,
	address = {Beijing, China},
	title = {Knowledge {Graph} {Embedding} via {Dynamic} {Mapping} {Matrix}},
	url = {https://aclanthology.org/P15-1067},
	doi = {10.3115/v1/P15-1067},
	urldate = {2022-01-28},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ji, Guoliang and He, Shizhu and Xu, Liheng and Liu, Kang and Zhao, Jun},
	month = jul,
	year = {2015},
	pages = {687--696},
	file = {Full Text PDF:C\:\\Users\\larsj\\Zotero\\storage\\SVU8WUKN\\Ji et al. - 2015 - Knowledge Graph Embedding via Dynamic Mapping Matr.pdf:application/pdf},
}

@book{fensel_introduction_2020,
	address = {Cham},
	title = {Introduction: {What} {Is} a {Knowledge} {Graph}?},
	isbn = {978-3-030-37439-6},
	shorttitle = {Introduction},
	url = {https://doi.org/10.1007/978-3-030-37439-6_1},
	abstract = {Since its inception by Google, Knowledge Graph has become a term that is recently ubiquitously used yet does not have a well-established definition. This section attempts to derive a definition for Knowledge Graphs by compiling existing definitions made in the literature and considering the distinctive characteristics of previous efforts for tackling the data integration challenge we are facing today. Our attempt to make a conceptual definition is complemented with an empirical survey of existing Knowledge Graphs. This section lays the foundation for the remainder of the book, as it provides a common understanding on certain concepts and motivation to build Knowledge Graphs in the first place.},
	language = {en},
	urldate = {2022-02-03},
	publisher = {Springer International Publishing},
	author = {Fensel, Dieter and {\c S}im{\c s}ek, Umutcan and Angele, Kevin and Huaman, Elwin and K{\"a}rle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, J{\"u}rgen and Wahler, Alexander},
	editor = {Fensel, Dieter and {\c S}im{\c s}ek, Umutcan and Angele, Kevin and Huaman, Elwin and K{\"a}rle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, J{\"u}rgen and Wahler, Alexander},
	year = {2020},
	doi = {10.1007/978-3-030-37439-6_1},
}
